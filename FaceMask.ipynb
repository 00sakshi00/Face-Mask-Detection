{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN4mbjHWnSnKgzjVour6sC6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/00sakshi00/Face-Mask-Detection/blob/main/FaceMask.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "jZMEaiwVrq0_"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# configuring the path of Kaggle.json file\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "uSyPJYK8yBVz"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importing Face Mask Dataset"
      ],
      "metadata": {
        "id": "l7fawUaXyqxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d omkargurav/face-mask-dataset"
      ],
      "metadata": {
        "id": "8v9xdXR-ysh1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracting the compessed Dataset\n",
        "from zipfile import ZipFile\n",
        "dataset = '/content/face-mask-dataset.zip'\n",
        "\n",
        "with ZipFile(dataset,'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('The dataset is extracted')"
      ],
      "metadata": {
        "id": "iwvdxyPszoKZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "id": "WbvF9aAZ0nIC"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Importing** **the** **Dependencies**"
      ],
      "metadata": {
        "id": "DZ3jiq_A1Tnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os #access files\n",
        "import numpy as np #convert imgaes to arrays\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from PIL import Image \n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "yvEvR9-z1mY4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with_mask_files = os.listdir('/content/data/with_mask')\n",
        "print(with_mask_files[0:5])\n",
        "print(with_mask_files[-5:])"
      ],
      "metadata": {
        "id": "bgs9QlPXXqIf"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "without_mask_files = os.listdir('/content/data/without_mask')\n",
        "print(without_mask_files[0:5])\n",
        "print(without_mask_files[-5:])"
      ],
      "metadata": {
        "id": "jMrtQ3b3Xs9S"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Number of with mask images:', len(with_mask_files))\n",
        "print('Number of without mask images:', len(without_mask_files))\n"
      ],
      "metadata": {
        "id": "MPYVrR3_XvjN"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Labels for the two class of Images**"
      ],
      "metadata": {
        "id": "02WUKstsX2Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "with mask --> 1\n",
        "\n",
        "without mask --> 0"
      ],
      "metadata": {
        "id": "Xb6qqvYrX90T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the labels\n",
        "with_mask_labels = [1]*3725\n",
        "without_mask_labels = [0]*3828"
      ],
      "metadata": {
        "id": "bCgQKXiIYA64"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(with_mask_labels[0:5])\n",
        "print(without_mask_labels[0:5])\n",
        "\n",
        "print(len(with_mask_labels))\n",
        "print(len(without_mask_labels))"
      ],
      "metadata": {
        "id": "cEeCjMu9YKal"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "labels = with_mask_labels + without_mask_labels\n",
        "\n",
        "print(len(labels))\n",
        "print(labels[0:5])\n",
        "print(labels[-5:])"
      ],
      "metadata": {
        "id": "OrlHS2TSYaSG"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying with mask image\n",
        "img = mpimg.imread('/content/data/with_mask/with_mask_2590.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zS00uKCNYd8b"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# displaying without mask image\n",
        "img = mpimg.imread('/content/data/without_mask/without_mask_2925.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uRg0-HoOZbH5"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Image Processing**"
      ],
      "metadata": {
        "id": "9LOMZDvsZ-MM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   Resize the Images\n",
        "*   Convert the Imgaes to numpy arrays"
      ],
      "metadata": {
        "id": "w5PRYjcwaCdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#convert images to numpy arrays\n",
        "\n",
        "with_mask_path = '/content/data/with_mask/' # /added in path\n",
        "\n",
        "data=[]\n",
        "\n",
        "for img_file in with_mask_files:\n",
        "  image = Image.open(with_mask_path + img_file)\n",
        "  image= image.resize((128,128)) #make all images of same size\n",
        "  image= image.convert('RGB') #some images may be gray scale\n",
        "  image= np.array(image)\n",
        "  data.append(image) \n",
        "\n",
        "\n",
        "\n",
        "without_mask_path = '/content/data/without_mask/' \n",
        "\n",
        "for img_file in without_mask_files:\n",
        "  image = Image.open(without_mask_path + img_file)\n",
        "  image= image.resize((128,128))\n",
        "  image= image.convert('RGB')\n",
        "  image= np.array(image)\n",
        "  data.append(image) "
      ],
      "metadata": {
        "id": "wCwHYGhraWLq"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data)\n",
        "len(data)"
      ],
      "metadata": {
        "id": "t7pLZOgIgvmc"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0]"
      ],
      "metadata": {
        "id": "TEGEoIhnhTCa"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(data[0])   # ndarray => n dimensional array"
      ],
      "metadata": {
        "id": "MS7b-esNhcK2"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[0].shape"
      ],
      "metadata": {
        "id": "3Ieb909ChiJt"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# converting image list and label list to numpy arrays\n",
        "\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)"
      ],
      "metadata": {
        "id": "p3bjnPRjh6B4"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(X)\n",
        "type(Y)"
      ],
      "metadata": {
        "id": "eHms5YKSh9Hl"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)\n",
        "print(Y.shape)"
      ],
      "metadata": {
        "id": "SiWDaovMiChu"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train Test Split**"
      ],
      "metadata": {
        "id": "2QekFzc0izMj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)"
      ],
      "metadata": {
        "id": "OuD7nFtzi4AH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape, X_train.shape, X_test.shape)"
      ],
      "metadata": {
        "id": "JIsMlqXLkCLn"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# scaling the data\n",
        "\n",
        "X_train_scaled = X_train/255\n",
        "X_test_scaled = X_test/255"
      ],
      "metadata": {
        "id": "xp2d2pJxkqdd"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[0]"
      ],
      "metadata": {
        "id": "tl-pwSrpkuVe"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_scaled[0]"
      ],
      "metadata": {
        "id": "UDFaWlcVkxaJ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Building Convolution Neural Network**"
      ],
      "metadata": {
        "id": "0ipQ72pFk3tI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf         #build neural network developed by google\n",
        "from tensorflow import keras    #developed by facebook"
      ],
      "metadata": {
        "id": "exi7L7AAk_iY"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_of_classes = 2\n",
        "\n",
        "model = keras.Sequential()\n",
        "\n",
        "model.add(keras.layers.Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(128,128,3)))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Conv2D(64, kernel_size=(3,3), activation='relu'))\n",
        "model.add(keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "model.add(keras.layers.Flatten()) # 2D data to single dimensional\n",
        "\n",
        "model.add(keras.layers.Dense(128, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))  # avoid overfitting\n",
        "\n",
        "model.add(keras.layers.Dense(64, activation='relu'))\n",
        "model.add(keras.layers.Dropout(0.5))\n",
        "\n",
        "model.add(keras.layers.Dense(num_of_classes, activation='sigmoid')) # sigmoid for binary classification"
      ],
      "metadata": {
        "id": "l_7n6vxQmrxK"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compile the neural network\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['acc'])"
      ],
      "metadata": {
        "id": "O8QtHgQyrd_Z"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# training the neural network\n",
        "history = model.fit(X_train_scaled, Y_train, validation_split=0.1, epochs=5)"
      ],
      "metadata": {
        "id": "bBAI7L1Xrsxw"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evalution**"
      ],
      "metadata": {
        "id": "nAx92AkVsvuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(X_test_scaled, Y_test)\n",
        "print('Test Accuracy =', accuracy)"
      ],
      "metadata": {
        "id": "BtErXBIAsyz1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "h = history\n",
        "\n",
        "# plot the loss value\n",
        "plt.plot(h.history['loss'], label='train loss')\n",
        "plt.plot(h.history['val_loss'], label='validation loss')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# plot the accuracy value\n",
        "plt.plot(h.history['acc'], label='train accuracy')\n",
        "plt.plot(h.history['val_acc'], label='validation accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1W-zjRf2tNXZ"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Predictive System**"
      ],
      "metadata": {
        "id": "JFhMRVvNt4fz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_image_path = input('Path of the image to be predicted: ')\n",
        "\n",
        "input_image = cv2.imread(input_image_path)   # cv2=> to display using colab\n",
        "\n",
        "cv2_imshow(input_image)\n",
        "\n",
        "input_image_resized = cv2.resize(input_image, (128,128))\n",
        "\n",
        "input_image_scaled = input_image_resized/255\n",
        "\n",
        "input_image_reshaped = np.reshape(input_image_scaled, [1,128,128,3]) #for only one image\n",
        "\n",
        "input_prediction = model.predict(input_image_reshaped)\n",
        "\n",
        "print(input_prediction) # gives probability\n",
        "\n",
        "input_pred_label = np.argmax(input_prediction)\n",
        "\n",
        "print(input_pred_label)\n",
        "\n",
        "if input_pred_label == 1:\n",
        "  print('The person in the image is wearing a mask')\n",
        "else:\n",
        "  print('The person in the image is not wearing a mask')"
      ],
      "metadata": {
        "id": "Me65Y-ejt8oN"
      },
      "execution_count": 55,
      "outputs": []
    }
  ]
}